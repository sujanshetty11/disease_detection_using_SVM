{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4WOs6Q3GZiM",
        "outputId": "d7439472-970d-4183-e686-aaa13343c307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Confusion Matrix:\n",
            "[[4080   54]\n",
            " [   0  786]]\n",
            "\n",
            "Training Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99      4134\n",
            "           1       0.94      1.00      0.97       786\n",
            "\n",
            "    accuracy                           0.99      4920\n",
            "   macro avg       0.97      0.99      0.98      4920\n",
            "weighted avg       0.99      0.99      0.99      4920\n",
            "\n",
            "\n",
            "Training Accuracy Score:\n",
            "0.9890243902439024\n",
            "\n",
            "Testing Confusion Matrix:\n",
            "[[31  4]\n",
            " [ 3  4]]\n",
            "\n",
            "Testing Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90        35\n",
            "           1       0.50      0.57      0.53         7\n",
            "\n",
            "    accuracy                           0.83        42\n",
            "   macro avg       0.71      0.73      0.72        42\n",
            "weighted avg       0.84      0.83      0.84        42\n",
            "\n",
            "\n",
            "Testing Accuracy Score:\n",
            "0.8333333333333334\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Load datasets\n",
        "train_data = pd.read_csv('Training.csv')\n",
        "test_data = pd.read_csv('Testing.csv')\n",
        "\n",
        "# Drop any unnamed columns that may have been added during the CSV save process\n",
        "train_data = train_data.loc[:, ~train_data.columns.str.contains('^Unnamed')]\n",
        "test_data = test_data.loc[:, ~test_data.columns.str.contains('^Unnamed')]\n",
        "\n",
        "# Separate features and labels\n",
        "X_train = train_data.drop('skin_rash', axis=1)\n",
        "y_train = train_data['skin_rash']\n",
        "X_test = test_data.drop('itching', axis=1)\n",
        "y_test = test_data['itching']\n",
        "\n",
        "# Ensure that all columns present in train are also in test\n",
        "missing_cols_in_test = set(X_train.columns) - set(X_test.columns)\n",
        "for col in missing_cols_in_test:\n",
        "    X_test[col] = 0\n",
        "\n",
        "# Ensure the same column order\n",
        "X_test = X_test[X_train.columns]\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_columns = X_train.select_dtypes(include=['object']).columns\n",
        "numerical_columns = X_train.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Define preprocessing for numerical data (impute missing values and scale)\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Define preprocessing for categorical data (impute missing values and one-hot encode)\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_columns),\n",
        "        ('cat', categorical_transformer, categorical_columns)\n",
        "    ])\n",
        "\n",
        "# Create the SVM pipeline with preprocessing and model training\n",
        "svm_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', SVC(kernel='linear'))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "svm_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on training data\n",
        "y_train_pred = svm_pipeline.predict(X_train)\n",
        "\n",
        "# Predict on testing data\n",
        "y_test_pred = svm_pipeline.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Training Confusion Matrix:\")\n",
        "print(confusion_matrix(y_train, y_train_pred))\n",
        "\n",
        "print(\"\\nTraining Classification Report:\")\n",
        "print(classification_report(y_train, y_train_pred))\n",
        "\n",
        "print(\"\\nTraining Accuracy Score:\")\n",
        "print(accuracy_score(y_train, y_train_pred))\n",
        "\n",
        "print(\"\\nTesting Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "print(\"\\nTesting Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "print(\"\\nTesting Accuracy Score:\")\n",
        "print(accuracy_score(y_test, y_test_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AXRDmmI6OOez"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}